#import "assets/modules/_conf.typ": *
#import "assets/modules/articleFig.typ": articleFig
#import "assets/modules/personHandled.typ": personHandled

#let member = (
  // クラス, 名前
  (class: "J3A", name: "日比 瑛太", handled: [
    // 自分が担当したところ
    + システム開発
  ], handledResult: [
    // 自分が担当したところの結果
    + XXX
    + XXX
  ], futureIssues: [
    // 自分が担当したところの今後の課題・考察
    + XXX
  ]),
  (class: "J3A", name: "本田 楓", handled: [
    + ゲームUI、タイトルロゴ作成
    + ドットデザイン
    + 3D小物作成
  ], handledResult: [
    親しみやすいポップなデザインができたと思う。3Dではキャラクターの等身や雰囲気に合わせて小物を作成することができた。
  ], futureIssues: [
    ロゴデザインではアプリの親しみやすさを表すことができたのではないかと思う。UIとして、2D、3Dを想定したものは作成できたが、ドットの際に使用するものの作成が抜けていたのでこれから追加できるように準備していきたい。
  ]),
  (class: "J3A", name: "本間 晶", handled: [
    + キャラクターデザイン
    + Live2Dモデルの制作
  ], handledResult: [
    キャラクターデザインは全8種類、モデルは3体分完成した。プレイヤーにとって親しみやすいよう、動物をモチーフとしてキャラクターのデザインを行い、飽きがこないようなモデルの動きを製作した。
  ], futureIssues: [
    キャラクターに揺れものを追加して、視覚的情報量を多くし、飽きがこないようにする。動きがどのキャラクターでも比較的変わらないので、そのキャラクターだけの特有のモーションなどを追加することでプレイヤーのプレイ意欲を高められると考える。
  ]),
  (class: "J3A", name: "松浦 颯", handled: [
    + 3DCG関連のグラフィック
  ], handledResult: [
    ゲームに対応した表情差分付きの3DCGキャラクターを製作し裸眼立体視を利用した立体的に見えるゲーム演出を製作することができた。また、感情を表現するために複数のアニメーションを製作した。
  ], futureIssues: [
    今回は一定の位置関係からしか立体的に見ることができないようになってしまっているので、Head-coupled Perspectiveを利用してどの方向からでも立体的に見えるシステムを導入したい。また、キャラクターアニメーションだけではない演出を追加することでよりユーザーに楽しんでもらえるようにしたい。
  ]),
)

#let img-seq = figure(
  rect(image("assets/img/sequence_diagram.svg")),
  caption: [
    音声会話のシーケンス図
  ]
)

#show: doc => conf(
  title: (
    // 表題 - 和文
    jp: [音声認識を用いたキャラクター育成アプリケーションの開発],
    // 表題 - 英文
    en: [Development of Character Growing Application Using Speech Recognition],
  ),
  // メンバー
  member: member,
  // 指導教諭
  teacher: [辰巳 良美, 中山 智明],
  // 発表学科略号/発表番号
  header: [J03],
  doc,
)

= はじめに
#i 近年、青少年の間で「ヤバい」「エモい」といった単純な表現が多用され、国語力や表現力の低下が問題視されている。文部科学省の調査によると、効果的なコミュニケーションには「意思疎通」「協調性」「自己表現力」が不可欠とされている。しかし、適切な言葉を用いる力が不足しているために、日常会話で自分の意図を正確に伝えられないケースが増えていると考える。また、教育現場では社会性やコミュニケーション能力の低下が指摘されている。@mext-comm 一方、経団連の新卒採用に関するアンケート調査 @keidanren では、企業が採用選考で最も重視する要素が「コミュニケーション能力」であることが分かっている。これらの結果から、企業が求める能力と若年層が現実に持つスキルとの間に乖離が生じていると考えられる。こうした現状から我々は、普段から積極的にコミュニケーションを取る機会を提供することで、表現力やコミュニケーション能力の向上につながると考えた。

#i そこで本研究では、ユーザーがキャラクターとの対話によってコミュニケーション能力を向上させることを目的としたキャラクター育成アプリケーションの開発を行った。

= 論理・実験
== アプリケーションの概要
#articleFig(
  imgPath: "img/Plutchik_Dyads.svg",
  imgCaption: [プルチックの感情の輪 @plutchik],
)[#i 本アプリケーションはキャラクター育成ゲームである。ユーザーがキャラクターに対して話しかけることで、キャラクターが返答を行う。キャラクターはプルチックの感情の輪に基づいた8つの感情 @plutchik をシミュレーションし、ユーザーの発話内容に応じて感情を変化させる。感情の変化はキャラクターの表情や口調に反映される。一定回数の会話を行うとキャラクターが進化し、感情の出現割合によってその進化先が分岐する。ユーザーはキャラクターの感情を観察することで、自分の発話内容が相手にどのような影響を与えるかを学ぶことができる。]

== デザイン面について
#i キャラクターデザインはドット絵、Live2D、3Dの3種類を製作し、キャラクター進化に3つの段階を設けた。ドット絵のモデルでは、プレイヤーにキャラクターの進化先を予測されないように、表情差分を5種類、カラーバリエーションを7種類製作した。Live2Dモデルでは、プレイヤーが親しみやすいように動物をモチーフとしたキャラクターデザインを行った。また、愛着を持ってもらいやすいよう、首を傾げたり尻尾が揺れるなどの可愛らしいモーションを製作した。3Dモデルでは5種類の表情差分を製作した。

#i 3Dの段階では、ゲームをより楽しんでもらうための効果として、裸眼立体視に挑戦した。裸眼立体視は錯視効果の一種で、3DメガネやHMD（ヘッドマウントディスプレイ）を使わずに立体視を楽しむことができる。

== システム面について
#i ゲームエンジンには、Live2Dとの互換性の関係からUnityを採用した。音声認識にはOpenAIのWhisperを採用し、ユーザーの発話内容をテキストに変換する。Whisperは他の音声認識に比べてその精度が高く、また多言語に対応していることからこれを採用した。キャラクターとの会話にはGPT-4o miniを使用し、テキスト生成の前に、キャラクターの感情として「喜び」「信頼」「恐れ」「驚き」「悲しみ」「嫌悪」「怒り」「期待」の8つを0～9の10段階（以下「感情値という」）でシミュレーションしている。感情値はキャラクターの口調や表情などに反映され、また感情値の出現割合によって1段階目の進化先が分岐し、キャラクターの性格に影響を与える。

#i 音声会話の実装は次のようになっている。

#img-seq

#i ユーザーの音声はAWS Lambdaを通じてWhisperへ送られ、文字起こしが行われる。この文章はこれまでの会話履歴と合わせてGPT-4o miniに入力され、会話文と感情値の生成が行われる。生成された会話文はVOICEVOXにより音声に変換された後、感情値とともにクライアントへ送られる。

== 感情シミュレーションについての実験
#i 本番環境と同じシステムプロンプトを入力したアシスタントに対して、8感情から「喜び」「恐れ」「悲しみ」「怒り」の4感情を引き出すであろうプロンプトをそれぞれ100パターン入力し、シミュレーションの正確性を確認した。正誤判定は、当該の感情値が最も高い値であるか否かで行った。

= 実験結果
== システム面
#i 感情シミュレーションに関する実験の結果は次のようになった。

#figure(
  image("assets/img/accuracy_plot.svg"),
  caption: [感情シミュレーションの実験結果]
)
#i

#i 「喜び」と「悲しみ」についてはそれぞれ8割以上、「恐れ」についても7割ほどの精度を確認したが、「怒り」についてはわずか9%とかなり低い値となり、ほとんどのパターンで感情値が0～1を示していた。

= 比較・考察
#i この結果の理由として、学習時のチューニングによる影響が考えられる。このようなAIを公開するにあたって、開発者は倫理的課題をある程度クリアする必要がある。そのため、学習データに存在するなどのチューニングを行っていることがほとんどである。ChatGPTはこれについて、事前学習した言語モデルを強化学習などによって再調整し、ここでバイアスなども同時に調整している。@openai このことから、ChatGPTはユーザーに対立するような生成を制限されているのだと考えられる。

= 結論
#i あのイーハトーヴォのすきとおった風、夏でも底に冷たさをもつ青いそら、うつくしい森で飾られたモリーオ市、郊外のぎらぎらひかる草の波。

= 今後の課題
#i あのイーハトーヴォのすきとおった風、夏でも底に冷たさをもつ青いそら、うつくしい森で飾られたモリーオ市、郊外のぎらぎらひかる草の波。

= 引用文献
#bibliography("refs.yml", title: [])

#pagebreak()
#for p in member {
  personHandled(
    //
    person: p,
    handled: p.handled,
    handledResult: p.handledResult,
    futureIssues: p.futureIssues,
  )
  if p.name != member.last().name {
    hr
  }
}